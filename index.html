<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./styles.css"/>
    <title>Emotion AI</title>
</head>
<body>
    <nav class="nav">
        <h1>Face Emotion AI</h1>
        
        
    </nav>
    <audio class="warning" id="warningAudio" >
      
        <source src="./sound2.mp3" />
      </audio>
    <div class="warningText" >
        <h1 class="warningHeading"></h1>
    </div>



 



















    <video id="webcam" autoplay>
      
    </video>


    <!-- script start from here -->

    <script src="https://ai-sdk.morphcast.com/v1.16/ai-sdk.js"></script>
    <script>

        // this is for alaram when no face
        const config = {smoothness: 0.83,timeWindowMs: 10000, initialToleranceMs: 7000, threshold: 0.75};
loader = CY.loader()
    CY.loader()
      .licenseKey("49b35cc0ec6cdf2aa3d527a6b9f82a4bde87e9f5b22a")
      .addModule(CY.modules().FACE_DETECTOR.name) //this detect the face
      .addModule(CY.modules().FACE_GENDER.name)  //this detect the gender
      .addModule(CY.modules().ALARM_NO_FACE.name, config) // this detect presence of person is in view or not
      .addModule(CY.modules().FACE_ATTENTION.name, config) //this will detect the attention level of the user for 0 - 1
      .addModule(CY.modules().FACE_EMOTION.name, config) //this is for emotions
      .load()
      .then(({ start, stop }) => start());
    
    window.addEventListener(CY.modules().FACE_DETECTOR.eventName, (evt) => {
    //   console.log('Face detector result', evt.detail);
    });



    // face gender logic start here
    window.addEventListener(CY.modules().FACE_GENDER.eventName, (evt) => {
//   console.log('Gender result', evt.detail.output.mostConfident);
});


//   this is for alarm
// let shouldPlaySound = true
let handleFaceDetection=""
  window.addEventListener(CY.modules().ALARM_NO_FACE.eventName, (evt) => {
    if (evt.detail.output.noFace == true) {
      let warning = document.querySelector(".warning");
      let warningHeading = document.querySelector(".warningHeading")
      warningHeading.innerText="Please look at the camera "
        handleFaceDetection="true"
      console.log("Please look at the camera");
      warning.play();
      console.log(handleFaceDetection)
    
    } else {
      let warning = document.querySelector(".warning");
      let warningHeading = document.querySelector(".warningHeading")
      warningHeading.innerText=""
        handleFaceDetection="false"
      // console.log("It's okay now");
      warning.pause()
      // console.log(handleFaceDetection)
      }
  });
  console.log("this is face deteciton value",handleFaceDetection)








// face attension registraion
window.addEventListener(CY.modules().FACE_ATTENTION.eventName, (evt) => {
    let attensionValue = evt.detail.output.attention
//   console.log('Face attention result', attensionValue);
});

// emotion value registraiton
window.addEventListener(CY.modules().FACE_EMOTION.eventName, (evt) => {
  console.log('Emotion result', evt.detail.output.dominantEmotion);
let blockNaming="hello how are you "
});


    </script>

    <!-- adding custom webcam -->
    <script>
        // Access the webcam using getUserMedia
        navigator.mediaDevices.getUserMedia({ video: true })
          .then((stream) => {
            let video = document.getElementById('webcam');
            video.srcObject = stream;
          })
          .catch((err) => {
            console.error('Error accessing the webcam: ', err);
          });




//   controlling audio

let shouldPlaySound=true
function toggleSound() {
  let audio = document.getElementById("warningAudio");
  
  if (shouldPlaySound) {
    audio.setAttribute('autoplay', '');
    audio.setAttribute('loop', '');
  } else {
    audio.removeAttribute('autoplay');
    audio.removeAttribute('loop');
  }
}





      </script>
    ...
    </body>
</html>